{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSSfXNwOPuhdlH68l6yXp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blegried93/New-Projects/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "# Display options\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"Default setup loaded!\")"
      ],
      "metadata": {
        "id": "Q-K27OERyoF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier as xgbC\n",
        "from xgboost import XGBRegressor as xgbR\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sT7KA7lB5lWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['MedHouseVal'] = data.target\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "rIxr2xER6dOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score # Import mean_squared_error and r2_score\n",
        "\n",
        "# Function to train and save predictions\n",
        "#Test_size is the complement of the training_size\n",
        "def train_and_save_predictions(test_size):\n",
        "    # Load data\n",
        "    data = fetch_california_housing()\n",
        "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "    df['MedHouseVal'] = data.target\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = tts(df.drop('MedHouseVal', axis=1), df['MedHouseVal'],\n",
        "                                            test_size=test_size, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = xgb.XGBRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
        "    error1 = compute_error_metrics(y_test,predictions)\n",
        "\n",
        "    # Create the 'data' directory if it doesn't exist\n",
        "    output_dir = '../data'  # Directory for saving predictions\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save results\n",
        "    filename = os.path.join(output_dir, f'predictions_testsize_{test_size}.csv')\n",
        "    comparison_df.to_csv(filename, index=False)\n",
        "    print(f\"mse, rmse, r2 are {error1}\")\n",
        "    print(f\"Predictions saved to {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_save_predictions(test_size)\n"
      ],
      "metadata": {
        "id": "U4VTxpi5Rnbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prints predictions from training\n",
        "def print_predictions(test_size):\n",
        "    filename = f'../data/predictions_testsize_{test_size}.csv'\n",
        "    df = pd.read_csv(filename)\n",
        "    print(f\"\\nPredictions for test_size={test_size}:\\n\")\n",
        "    print(df.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print_predictions(test_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrH152kz_O_1",
        "outputId": "e88bf427-be3a-47d5-bcd3-63febecf5883"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions for test_size=0.3:\n",
            "\n",
            "    Actual  Predicted\n",
            "0  0.47700   0.610555\n",
            "1  0.45800   0.550802\n",
            "2  5.00001   4.765771\n",
            "3  2.18600   2.568251\n",
            "4  2.78000   2.404391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_results(test_size):\n",
        "    filename = f'../data/predictions_testsize_{test_size}.csv'\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(df['Actual'], df['Predicted'], alpha=0.5)\n",
        "    plt.plot([df['Actual'].min(), df['Actual'].max()],\n",
        "             [df['Actual'].min(), df['Actual'].max()], color='red')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title(f'Actual vs Predicted Values (test_size={test_size})')\n",
        "    plt.grid()\n",
        "\n",
        "    # Save plot\n",
        "    plt.show()\n",
        "    plot_filename = f'../data/plot_testsize_{test_size}.png'\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "    print(f\"Plot saved to {plot_filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    plot_results(test_size)\n"
      ],
      "metadata": {
        "id": "_Dav37bg_vZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_error_metrics(y_true,y_pred):\n",
        "  mse = mean_squared_error(y_true,y_pred)\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = r2_score(y_true,y_pred)\n",
        "\n",
        "  return mse, rmse, r2"
      ],
      "metadata": {
        "id": "frAlUrxBl1ju"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "#Driver file for the previous 3 steps.\n",
        "def run_experiment(test_size):\n",
        "    print(f\"\\nRunning experiment with test_size={test_size}...\\n\")\n",
        "    train_and_save_predictions(test_size)\n",
        "    print_predictions(test_size)\n",
        "    plot_results(test_size)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_sizes = [0.1, 0.5, 0.9]\n",
        "    for test_size in test_sizes:\n",
        "        run_experiment(test_size)"
      ],
      "metadata": {
        "id": "LjldHLzrFDjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}